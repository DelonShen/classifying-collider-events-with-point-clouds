{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR in cling::CIFactory::createCI(): cannot extract standard library include paths!\n",
      "Invoking:\n",
      "  LC_ALL=C x86_64-conda-linux-gnu-c++  -O3 -DNDEBUG -xc++ -E -v /dev/null 2>&1 | sed -n -e '/^.include/,${' -e '/^ \\/.*++/p' -e '}'\n",
      "Results was:\n",
      "With exit code 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 12:00:03.222754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 12:00:03.222794: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Experimenter\n",
      "\tLoading Data from ../data/data50k_raw_combined_atlas_cut_small.pkl\n",
      "\tData Loaded\n",
      "\tCreating Splits\n",
      "\tSplits Created\n",
      "Done initalizing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import experiment\n",
    "import pickle\n",
    "from utils import *\n",
    "from Architectures import *\n",
    "import random, os\n",
    "suppress_warnings()\n",
    "EPOCHS = 256\n",
    "\n",
    "\n",
    "def countp(model, params):\n",
    "    tmp = model(**params)\n",
    "    tmp.build(input_shape=(1,15,7))\n",
    "    return tmp.count_params()\n",
    "\n",
    "\n",
    "scan = [7]\n",
    "n_params = []\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def human_format(num):\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    # add more suffixes if you need them\n",
    "    return '%.0f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])\n",
    "\n",
    "\n",
    "filename = '../data/data100k_raw_combined_atlas_cut.pkl'\n",
    "n_experiments = 8\n",
    "SUFFIX = '_latent_dim_edge_AeqB_only_1_2'\n",
    "\n",
    "\n",
    "#TESTING ######\n",
    "EPOCHS = 2\n",
    "filename = '../data/data50k_raw_combined_atlas_cut_small.pkl'\n",
    "n_experiments = 2\n",
    "SUFFIX = '_latent_dim_edge_TEST'\n",
    "###########\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PI = experiment.Experimenter(filename)\n",
    "from datetime import datetime\n",
    "\n",
    "AUCs=[]\n",
    "e03i = []\n",
    "e03 = []\n",
    "e07i = []\n",
    "e07 = []\n",
    "nn_AUC = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect \n",
    "\n",
    "PI.data_loader('pairwise', gen_multijet_to_inv_dataset, class_weight_invariant, tf.constant, aux_params=dict(dR_keep=False, multijet_n=1))\n",
    "for i in scan:\n",
    "    curr_auc = []\n",
    "    print(\"\\t\\tLATENT DIM\", 2**i)\n",
    "    for j in range(n_experiments):\n",
    "        tf.random.set_seed(42+j)\n",
    "        np.random.seed(42+j)\n",
    "        random.seed(42+j)\n",
    "        tail_string = PI.get_tail_string({'depth':5, 'ec_widths':(64,128,256,128,2**i), 'width':64})\n",
    "        classifier_name = '%s_%s'%('pairwise', tail_string)\n",
    "\n",
    "        if(classifier_name in PI.models):\n",
    "            del PI.models[classifier_name]\n",
    "            del PI.perf[classifier_name]\n",
    "\n",
    "        PI.train_classifier('pairwise', {'depth':5, 'ec_widths':(64,128,256,128,2**i), 'width':64}, epochs=EPOCHS, seed=42+j)\n",
    "\n",
    "\n",
    "        fpr, tpr, thresholds, auc = PI.get_ROC('pairwise', {'depth':5, 'ec_widths':(64,128,256,128,2**i), 'width':64})\n",
    "        curr_auc.append(auc)\n",
    "        location_0 = bisect.bisect_left(tpr, 0.7)\n",
    "        location = bisect.bisect_left(tpr, 0.3)\n",
    "        e03i.append(1/fpr[location-1])\n",
    "        e03.append((tpr)[location-1]/fpr[location-1])\n",
    "        e07i.append(1/fpr[location_0-1])\n",
    "        e07.append((tpr)[location_0-1]/fpr[location_0-1])\n",
    "        if(j==0):\n",
    "            n_params.append(human_format(PI.models[classifier_name].count_params()))\n",
    "    AUCs.append(curr_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mean_std(lst,a):\n",
    "    return np.array([np.mean(curr) for curr in lst])[a], np.array([np.std(curr) for curr in lst])[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(lst,a):\n",
    "    return np.array([np.mean(curr) for curr in lst])[a], np.array([np.std(curr) for curr in lst])[a]\n",
    "\n",
    "e03 = np.reshape(e03, (1,8))\n",
    "e03i = np.reshape(e03i, (1,8))\n",
    "\n",
    "e07 = np.reshape(e07, (1,8))\n",
    "e07i = np.reshape(e07i, (1,8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in scan:\n",
    "    print('$2^%d$ & $%.3f \\pm %.3f$ & %s & $%.1f\\pm %.1f$ & $%.1f\\pm %.1f$ & $%.1f\\pm %.1f$ & $%.1f\\pm %.1f$\\\\\\\\\\n'%(a, *mean_std(AUCs,a),n_params[a],\n",
    "                                                                                                                                *mean_std(e03i,a),\n",
    "                                                                                                                                *mean_std(e03,a),\n",
    "                                                                                                                                *mean_std(e07i,a),\n",
    "                                                                                                                                *mean_std(e07,a), \n",
    "                                                                                                                                ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcec",
   "language": "python",
   "name": "pcec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
